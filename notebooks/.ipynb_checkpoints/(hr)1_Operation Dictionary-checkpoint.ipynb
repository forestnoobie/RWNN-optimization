{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Representation for Efficient Architecture search\n",
    "* 참고 링크 : https://openreview.net/pdf?id=BJQRKzbA-\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img1](../images/hier.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](../images/hier2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* operation_dict, adjacency matrix G 구현 -> 이중 리스트로 구현\n",
    "* models.py의 Node_op 부분에 추가 파라미터를 주어서 변경한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Operation Dictionary (operation set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "구현 목록\n",
    "* operation dictionary global  생성 \n",
    "* 키 값에 해당하는 함수 만들 리턴 -> 함수마다 파라미터 값이 다르기 때문에 이 부분 주의해야 (conv, maxpool)\n",
    "* Triplet unit 에 parameter 추가해서 적용\n",
    "* 임의의 텐서 만들어서 넣어봐서 사이즈 변화를 관찰하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0,'../')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from utils_kyy import models\n",
    "\n",
    "print(torch.__version__)\n",
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 : 1 x 1 conv\n",
    "1 : 3 x 3  depthwise conv\n",
    "2 : 3 X 3 seperable conv\n",
    "3 : 3 x 3 depthwise seperable conv\n",
    "3 : max pooling\n",
    "4 : average pooling\n",
    "5 : Identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import math\n",
    "\n",
    "from utils_kyy.utils_graph import load_graph, get_graph_info\n",
    "\n",
    "class depthwise_separable_conv_3x3(nn.Module):\n",
    "    def __init__(self, nin, nout, stride):\n",
    "        # input node 일때, stride = 1; => size 유지\n",
    "        # input node 아닐 대, stride = 2; =>  (x-1)/2 + 1\n",
    "        super(depthwise_separable_conv_3x3, self).__init__()\n",
    "        self.depthwise = nn.Conv2d(nin, nin, kernel_size=3, stride=stride, padding=1, groups=nin)\n",
    "        self.pointwise = nn.Conv2d(nin, nout, kernel_size=1)  # default: stride=1, padding=0, dilation=1, groups=1, bias=True\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.depthwise(x)\n",
    "        out = self.pointwise(out)\n",
    "        return out\n",
    "\n",
    "class conv2d_3x3(nn.Module):\n",
    "    def __init__(self, nin, nout, stride):\n",
    "        super(conv2d_3x3, self).__init__()\n",
    "        self.conv = nn.Conv2d(nin, nout, kernel_size=3, stride=stride, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        return out\n",
    "\n",
    "class depthwise_conv_3x3(nn.Module):\n",
    "    def __init__(self, nin, nout, stride):\n",
    "        # input node 일때, stride = 1; => size 유지\n",
    "        # input node 아닐 대, stride = 2; =>  (x-1)/2 + 1\n",
    "        super(depthwise_conv_3x3, self).__init__()\n",
    "        self.depthwise = nn.Conv2d(nin, nout, kernel_size=3, stride=stride, padding=1, groups=nin)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.depthwise(x)\n",
    "        return out\n",
    "\n",
    "class separable_conv_3x3(nn.Module):\n",
    "    def __init__(self, nin, nout, stride):\n",
    "        # input node 일때, stride = 1; => size 유지\n",
    "        # input node 아닐 대, stride = 2; =>  (x-1)/2 + 1\n",
    "        super(separable_conv_3x3, self).__init__()\n",
    "        self.pointwise = nn.Conv2d(nin, nout, kernel_size=3, stride=stride)  # default: stride=1, padding=0, dilation=1, groups=1, bias=True\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.pointwise(x)\n",
    "        return out\n",
    "\n",
    "class maxpool2d_3x3(nn.Module):\n",
    "    def __init__(self, nin, nout, stride):\n",
    "        super(maxpool2d_3x3, self).__init__()\n",
    "        self.conv = nn.MaxPool2d(kernel_size=3, stride=stride, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        return out\n",
    "\n",
    "class avgpool2d_3x3(nn.Module):\n",
    "    def __init__(self, nin, nout, stride):\n",
    "        super(avgpool2d_3x3, self).__init__()\n",
    "        self.conv = nn.AvgPool2d(kernel_size=3, stride=stride, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        return out\n",
    "    \n",
    "class identity(nn.Module):\n",
    "    def __init__(self, nin, nout, stride):\n",
    "        # input node 일때, stride = 1; => size 유지\n",
    "        # input node 아닐 대, stride = 2; =>  (x-1)/2 + 1\n",
    "        super(identity, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        return out\n",
    " \n",
    "    \n",
    "class Triplet_unit(nn.Module):\n",
    "    def __init__(self, inplanes, outplanes, stride=1):\n",
    "        super(Triplet_unit, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv = depthwise_separable_conv_3x3(inplanes, outplanes, stride)\n",
    "        self.bn = nn.BatchNorm2d(outplanes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(x)\n",
    "        out = self.conv(out)\n",
    "        out = self.bn(out)\n",
    "        return out\n",
    "\n",
    "## new triplet_unint\n",
    "class Triplet_unit(nn.Module):\n",
    "    def __init__(self, inplanes, outplanes, operation=1, stride=1):\n",
    "        super(Triplet_unit, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.operation = 1\n",
    "    \n",
    "        self.conv = depthwise_separable_conv_3x3(inplanes, outplanes, stride)\n",
    "        self.bn = nn.BatchNorm2d(outplanes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(x)\n",
    "        out = self.conv(out)\n",
    "        out = self.bn(out)\n",
    "        return out\n",
    "\n",
    "    \n",
    "class Node_OP(nn.Module):\n",
    "    def __init__(self, Node, inplanes, outplanes):\n",
    "        super(Node_OP, self).__init__()\n",
    "        self.is_input_node = Node.type == 0\n",
    "        self.input_nums = len(Node.inputs)    # 해당 Node에 input으로 연결된 노드의 개수\n",
    "\n",
    "        # input 개수가 1보다 크면, 여러 input을 합쳐야함.\n",
    "        if self.input_nums > 1:\n",
    "            self.mean_weight = nn.Parameter(torch.ones(self.input_nums))  # type: torch.nn.parameter.Parameter\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        if self.is_input_node:\n",
    "            self.conv = Triplet_unit(inplanes, outplanes, stride=2)   # Triplet_unit = relu, conv, bn\n",
    "        else:\n",
    "            self.conv = Triplet_unit(outplanes, outplanes, stride=1)\n",
    "\n",
    "    # [참고] nn.Sigmoid()(torch.ones(1)) = 0.7311\n",
    "    # seoungwonpark source 에서는 torch.zeros()로 들어감. => 0.5\n",
    "    def forward(self, *input):\n",
    "        if self.input_nums > 1:\n",
    "            out = self.sigmoid(self.mean_weight[0]) * input[0]\n",
    "            for i in range(1, self.input_nums):\n",
    "                out = out + self.sigmoid(self.mean_weight[i]) * input[i]\n",
    "        else:\n",
    "            out = input[0]\n",
    "        out = self.conv(out)\n",
    "        return out\n",
    "\n",
    "    \n",
    "\n",
    "class StageBlock(nn.Module):\n",
    "    def __init__(self, graph, inplanes, outplanes):\n",
    "        super(StageBlock, self).__init__()\n",
    "        # graph를 input으로 받아서, Node_OP class. 즉, neural network graph로 전환함.\n",
    "        self.nodes, self.input_nodes, self.output_nodes = get_graph_info(graph)\n",
    "        self.nodeop  = nn.ModuleList()    # Holds submodules in a list.\n",
    "        for node in self.nodes:\n",
    "            # 각각의 node들을 Node_OP class로 만들어준 뒤, nn.ModuleList()인 self.nodeop에 append 해주기\n",
    "            self.nodeop.append(Node_OP(node, inplanes, outplanes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        results = {}\n",
    "        # input\n",
    "        for id in self.input_nodes:\n",
    "            results[id] = self.nodeop[id](x)  # input x를 먼저 graph's input node에 각각 넣어줌.\n",
    "\n",
    "        # graph 중간 계산\n",
    "        for id, node in enumerate(self.nodes):\n",
    "            # 각각의 노드 id에 대해\n",
    "            if id not in self.input_nodes:\n",
    "                # graph's input node가 아니라면, 그래프 내에서 해당 노드의 인풋들인 node.inputs의 output인 results[_id]\n",
    "                #    => 그 결과를 results[id]에 저장.\n",
    "                # self.nodeop[id]는 해당 id의 Node_OP. 즉, input들을 받아서 forward(모아서, conv 태우기)하는 것.\n",
    "                # 따라서, input으로 넣을 때 unpack 함.\n",
    "                # id 작은 노드부터 result를 차근차근 계산하면서, id를 올라감.\n",
    "                results[id] = self.nodeop[id](*[results[_id] for _id in node.inputs])\n",
    "\n",
    "        result = results[self.output_nodes[0]]\n",
    "        # output\n",
    "        # graph's output_nodes의 output 들을 평균내기\n",
    "        for idx, id in enumerate(self.output_nodes):\n",
    "            if idx > 0:\n",
    "                result = result + results[id]\n",
    "        result = result / len(self.output_nodes)\n",
    "        return result\n",
    "   \n",
    " \n",
    "# Node_OP -> StageBlock class 정의해놓고,\n",
    "# conv2, conv3, conv4에 각각 random graph 생성해서 모듈로 추가함\n",
    "# e.g.\n",
    "#  graphs = EasyDict({'stage_1': stage_1_graph,\n",
    "#                     'stage_2': stage_2_graph,\n",
    "#                     'stage_3': stage_3_graph\n",
    "#  })   # stage_1_graph = 해당 graph 파일의 path\n",
    "# channels = 109\n",
    "\n",
    "class RWNN(nn.Module):\n",
    "    def __init__(self, net_type, graphs, channels, num_classes=1000, input_channel=3):\n",
    "        super(RWNN, self).__init__()\n",
    "\n",
    "        self.input_channel = input_channel\n",
    "        # 논문에서도 conv1 쪽은 예외적으로 Conv-BN 이라고 언급함. (나머지에서는 Conv-ReLU-BN 을 conv 로 표기) \n",
    "#         self.conv1 = depthwise_separable_conv_3x3(input_channel, channels // 2, 2)    # nin, nout, stride\n",
    "        self.conv1 = depthwise_separable_conv_3x3(input_channel, channels // 2, 1)    # nin, nout, stride        \n",
    "        self.bn1 = nn.BatchNorm2d(channels // 2)\n",
    "        \n",
    "        # 채널수 변화도, 논문에서처럼 conv2: C, conv3: 2C, conv4: 4C, conv5: 8C\n",
    "        if net_type == 'small':\n",
    "#             self.conv2 = Triplet_unit(channels // 2, channels, 2)    # inplanes, outplanes, stride=2\n",
    "            self.conv2 = Triplet_unit(channels // 2, channels, 1)    # inplanes, outplanes, stride=1            \n",
    "\n",
    "#             self.conv3 = StageBlock(graphs.stage_1, channels // 2, channels)\n",
    "            self.conv3 = StageBlock(graphs.stage_1, channels, channels)        \n",
    " \n",
    "            self.conv4 = StageBlock(graphs.stage_2, channels, channels * 2)   \n",
    "\n",
    "            self.conv5 = StageBlock(graphs.stage_3, channels * 2, channels * 4)\n",
    "\n",
    "            self.relu = nn.ReLU()\n",
    "            \n",
    "            self.bn2 = nn.BatchNorm2d(channels * 4)\n",
    "            self.avgpool = nn.AvgPool2d(4, stride=1)  # 마지막은 global average pooling\n",
    "            self.fc = nn.Linear(channels * 4, num_classes)\n",
    "\n",
    "#         if net_type == 'small':\n",
    "#             self.conv2 = Triplet_unit(channels // 2, channels, 2)    # inplanes, outplanes, stride=2\n",
    "\n",
    "#             self.conv3 = StageBlock(graphs.stage_1, channels, channels)\n",
    " \n",
    "#             self.conv4 = StageBlock(graphs.stage_2, channels, channels *2)   \n",
    "\n",
    "#             self.conv5 = StageBlock(graphs.stage_3, channels * 2, channels * 4)\n",
    "\n",
    "#             self.relu = nn.ReLU()\n",
    "# #             self.conv = nn.Conv2d(channels * 4, 1280, kernel_size=1)   # 마지막에 1x1 conv, 1280-d\n",
    "# #             self.bn2 = nn.BatchNorm2d(1280)\n",
    "        \n",
    "        #######################################\n",
    "        # 원 코드에서 regular 부분 지움\n",
    "        #######################################\n",
    "#         self.avgpool = nn.AvgPool2d(7, stride=1)  # 마지막은 global average pooling\n",
    "#         self.fc = nn.Linear(1280, num_classes)\n",
    "    \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "#         print(\"==========Data Size\", x.size())\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "#         print(\"==========Conv1 Size\", x.size())  # => (-, 54, 16, 16)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "#         print(\"==========Conv2  Size\", x.size())  # => (-, 109, 8, 8)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "#         print(\"==========Conv3  Size\", x.size())  # => (-, 109, 8, 8)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "#         print(\"==========Conv4  Size\", x.size())  # => (-, 218, 4, 4)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "#         print(\"==========Conv5  Size\", x.size())  # => (-, 436, 2, 2)\n",
    "\n",
    "#         x = self.relu(x)  # => (-, 436, 1, 1)\n",
    "#         x = self.conv(x)\n",
    "#         print(\"==========Conv6  Size\", x.size())  # => (-, 1280, 1, 1)\n",
    "\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "#         print(\"==========before avgpool  Size\", x.size())   ## [수정] CIFAR-10 에서는 여기까지오면 (-, 1280, 7, 7) 이 아니라 (-, ,1280, 1, 1)\n",
    "        x = self.avgpool(x)\n",
    "#         print(\"==========after avgpool  Size\", x.size())\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "###################################################    \n",
    "# #print(\"==========Data Size\", x.size())\n",
    "# x = self.conv1(x)\n",
    "# x = self.bn1(x)\n",
    "\n",
    "# x = self.conv2(x)\n",
    "# x = self.conv3(x)\n",
    "# x = self.conv4(x)\n",
    "# x = self.conv5(x)\n",
    "\n",
    "# x = self.relu(x)\n",
    "# x = self.conv(x)\n",
    "\n",
    "# x = self.bn2(x)\n",
    "# x = self.relu(x)\n",
    "# x = self.avgpool(x)\n",
    "\n",
    "# x = x.view(x.size(0), -1)\n",
    "# x = self.fc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def operation_dictionary():\n",
    "    temp_dict = {}\n",
    "    temp_dict[0] = conv2d_3x3 # nin, nout, kernel_size=3, stride=stride, padding=\n",
    "    temp_dict[1] = depthwise_conv_3x3 # nin, nout ,  stride\n",
    "    temp_dict[2] = separable_conv_3x3\n",
    "    temp_dict[3] = depthwise_separable_conv_3x3\n",
    "    temp_dict[4] = maxpool2d_3x3 # parameter Kernel_size , stride, padding\n",
    "    temp_dict[5] = avgpool2d_3x3\n",
    "    temp_dict[6] = identity\n",
    "    \n",
    "    return temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "oper_dict = operation_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: __main__.conv2d_3x3,\n",
       " 1: __main__.depthwise_conv_3x3,\n",
       " 2: __main__.separable_conv_3x3,\n",
       " 3: __main__.depthwise_separable_conv_3x3,\n",
       " 4: __main__.maxpool2d_3x3,\n",
       " 5: __main__.avgpool2d_3x3,\n",
       " 6: __main__.identity}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oper_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Operation 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.array([[[[1,0,0],\n",
    "             [0,0,0],\n",
    "             [0,0,0]],\n",
    "            [[0,0,0],\n",
    "            [0,0,0],\n",
    "            [0,0,0]],\n",
    "            [[0,0,0],\n",
    "            [0,0,0],\n",
    "            [0,0,0]]]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 3, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.conv2d_3x3'>\n",
      "==============================\n",
      " Result \n",
      "tensor([[[[-0.2049,  0.1401, -0.0421],\n",
      "          [-0.0809,  0.0158, -0.0421],\n",
      "          [-0.0421, -0.0421, -0.0421]],\n",
      "\n",
      "         [[ 0.0854,  0.2330,  0.0586],\n",
      "          [ 0.2352,  0.1584,  0.0586],\n",
      "          [ 0.0586,  0.0586,  0.0586]],\n",
      "\n",
      "         [[ 0.0670,  0.1142,  0.1676],\n",
      "          [ 0.1407,  0.3544,  0.1676],\n",
      "          [ 0.1676,  0.1676,  0.1676]]]], grad_fn=<ThnnConv2DBackward>)\n",
      "==============================\n",
      " Parameter \n",
      "[Parameter containing:\n",
      "tensor([[[[ 0.0578, -0.0388, -0.0424],\n",
      "          [ 0.1822, -0.1628,  0.0745],\n",
      "          [ 0.1262,  0.1321, -0.0093]],\n",
      "\n",
      "         [[-0.0481,  0.0705,  0.1737],\n",
      "          [-0.0493,  0.1760, -0.1607],\n",
      "          [-0.0215,  0.1035, -0.0457]],\n",
      "\n",
      "         [[ 0.0039,  0.0318, -0.1517],\n",
      "          [ 0.0531, -0.1897, -0.0113],\n",
      "          [ 0.1197, -0.1011,  0.0810]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0998,  0.1767, -0.0646],\n",
      "          [ 0.1744,  0.0269, -0.1647],\n",
      "          [ 0.0276, -0.0303,  0.0286]],\n",
      "\n",
      "         [[ 0.0006, -0.1863, -0.1442],\n",
      "          [-0.1001, -0.1235,  0.0360],\n",
      "          [ 0.0752, -0.1604,  0.1701]],\n",
      "\n",
      "         [[-0.1913,  0.1110,  0.0607],\n",
      "          [-0.0613, -0.0146,  0.0734],\n",
      "          [ 0.0509, -0.0805, -0.0349]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1867, -0.0269,  0.0030],\n",
      "          [-0.0534, -0.1006, -0.1115],\n",
      "          [-0.0575,  0.1130, -0.0020]],\n",
      "\n",
      "         [[ 0.0225, -0.0011, -0.1850],\n",
      "          [ 0.0736, -0.0304,  0.1571],\n",
      "          [-0.0362, -0.1468, -0.1251]],\n",
      "\n",
      "         [[ 0.0138, -0.0534,  0.1510],\n",
      "          [ 0.0051,  0.0813, -0.1386],\n",
      "          [ 0.1180, -0.1229,  0.0774]]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.0421,  0.0586,  0.1676], requires_grad=True)]\n",
      "==============================\n",
      " Tensor \n",
      "tensor([[[[1., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]]]])\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "operation  = oper_dict[idx]\n",
    "# (Batch size , Cin, H, W)\n",
    "tesnor_ex = torch.from_numpy(i)\n",
    "\n",
    "tesnor_ex.size()\n",
    "\n",
    "t = operation(3,3,stride=1)\n",
    "\n",
    "print(operation)\n",
    "print('='*30 + '\\n Result ' )\n",
    "print(t.forward(tesnor_ex))\n",
    "print('='*30 + '\\n Parameter ' )\n",
    "print(list(t.parameters()))\n",
    "print('='*30 + '\\n Tensor ' )\n",
    "print(tesnor_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.separable_conv_3x3'>\n",
      "==============================\n",
      " Result \n",
      "tensor([[[[ 0.3604,  0.4085,  0.4085],\n",
      "          [ 0.4085,  0.4085,  0.4085],\n",
      "          [ 0.4085,  0.4085,  0.4085]],\n",
      "\n",
      "         [[ 0.0270, -0.2240, -0.2240],\n",
      "          [-0.2240, -0.2240, -0.2240],\n",
      "          [-0.2240, -0.2240, -0.2240]],\n",
      "\n",
      "         [[-0.9502, -0.4955, -0.4955],\n",
      "          [-0.4955, -0.4955, -0.4955],\n",
      "          [-0.4955, -0.4955, -0.4955]]]], grad_fn=<ThnnConv2DBackward>)\n",
      "==============================\n",
      " Parameter \n",
      "[Parameter containing:\n",
      "tensor([[[[-0.0481]],\n",
      "\n",
      "         [[-0.4679]],\n",
      "\n",
      "         [[-0.4895]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2510]],\n",
      "\n",
      "         [[ 0.3011]],\n",
      "\n",
      "         [[ 0.4044]]],\n",
      "\n",
      "\n",
      "        [[[-0.4547]],\n",
      "\n",
      "         [[-0.4290]],\n",
      "\n",
      "         [[-0.2246]]]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.4085, -0.2240, -0.4955], requires_grad=True)]\n",
      "==============================\n",
      " Tensor \n",
      "tensor([[[[1., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]]]])\n"
     ]
    }
   ],
   "source": [
    "idx = 2\n",
    "operation  = oper_dict[idx]\n",
    "# (Batch size , Cin, H, W)\n",
    "tesnor_ex = torch.from_numpy(i)\n",
    "#tesnor_ex = torch.zeros([1,3,3,3])\n",
    "tesnor_ex.size()\n",
    "\n",
    "t = operation(3,3,stride=1)\n",
    "\n",
    "print(operation)\n",
    "print('='*30 + '\\n Result ' )\n",
    "print(t.forward(tesnor_ex))\n",
    "print('='*30 + '\\n Parameter ' )\n",
    "print(list(t.parameters()))\n",
    "print('='*30 + '\\n Tensor ' )\n",
    "print(tesnor_ex)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.maxpool2d_3x3'>\n",
      "==============================\n",
      " Result \n",
      "tensor([[[[1., 1., 0.],\n",
      "          [1., 1., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]]]]) torch.Size([1, 3, 3, 3])\n",
      "==============================\n",
      " Parameter \n",
      "[]\n",
      "==============================\n",
      " Tensor \n",
      "tensor([[[[1., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]]]])\n"
     ]
    }
   ],
   "source": [
    "idx = 4\n",
    "operation  = oper_dict[idx]\n",
    "# (Batch size , Cin, H, W)\n",
    "tesnor_ex = torch.from_numpy(i)\n",
    "#tesnor_ex = torch.zeros([1,3,3,3])\n",
    "tesnor_ex.size()\n",
    "\n",
    "t = operation(3,3,1)\n",
    "\n",
    "print(operation)\n",
    "print('='*30 + '\\n Result ' )\n",
    "print(t.forward(tesnor_ex), t.forward(tesnor_ex).size())\n",
    "print('='*30 + '\\n Parameter ' )\n",
    "print(list(t.parameters()))\n",
    "print('='*30 + '\\n Tensor ' )\n",
    "print(tesnor_ex)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TO DO \n",
    "Maxpooling -> 객체화\n",
    "identity 까지 검증하고  -> triplet 적용 -> 바로 실험 오늘까지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.avgpool2d_3x3'>\n",
      "==============================\n",
      " Result \n",
      "tensor([[[[0.1111, 0.1111, 0.0000],\n",
      "          [0.1111, 0.1111, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000]]]]) torch.Size([1, 3, 3, 3])\n",
      "==============================\n",
      " Parameter \n",
      "[]\n",
      "==============================\n",
      " Tensor \n",
      "tensor([[[[1., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]]]])\n"
     ]
    }
   ],
   "source": [
    "idx = 5\n",
    "operation  = oper_dict[idx]\n",
    "# (Batch size , Cin, H, W)\n",
    "tesnor_ex = torch.from_numpy(i)\n",
    "#tesnor_ex = torch.zeros([1,3,3,3])\n",
    "tesnor_ex.size()\n",
    "\n",
    "t = operation(3,3,1)\n",
    "\n",
    "print(operation)\n",
    "print('='*30 + '\\n Result ' )\n",
    "print(t.forward(tesnor_ex), t.forward(tesnor_ex).size())\n",
    "print('='*30 + '\\n Parameter ' )\n",
    "print(list(t.parameters()))\n",
    "print('='*30 + '\\n Tensor ' )\n",
    "print(tesnor_ex)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.identity'>\n",
      "==============================\n",
      " Result \n",
      "tensor([[[[1., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]]]]) torch.Size([1, 3, 3, 3])\n",
      "==============================\n",
      " Parameter \n",
      "[]\n",
      "==============================\n",
      " Tensor \n",
      "tensor([[[[1., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]]]])\n"
     ]
    }
   ],
   "source": [
    "idx = 6\n",
    "operation  = oper_dict[idx]\n",
    "# (Batch size , Cin, H, W)\n",
    "tesnor_ex = torch.from_numpy(i)\n",
    "#tesnor_ex = torch.zeros([1,3,3,3])\n",
    "tesnor_ex.size()\n",
    "\n",
    "t = operation(3,3,1)\n",
    "\n",
    "print(operation)\n",
    "print('='*30 + '\\n Result ' )\n",
    "print(t.forward(tesnor_ex), t.forward(tesnor_ex).size())\n",
    "print('='*30 + '\\n Parameter ' )\n",
    "print(list(t.parameters()))\n",
    "print('='*30 + '\\n Tensor ' )\n",
    "print(tesnor_ex)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Operation DIctionary 생성 완료"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'newrw'",
   "language": "python",
   "name": "newrw"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
