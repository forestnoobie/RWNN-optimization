{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Training \n",
    "구현해야 될 것\n",
    "* 모델 선정 리스트 만들기\n",
    "* 모델 생성\n",
    "* 훈련, hyper parameter는 기존과 동일, Termination 조건은 5 epoch 동인 Val acc 안 오를 경우\n",
    "* 중간에 끊겨도 중간에서 부터 돌릴 수 있게 하기\n",
    "* 로그 떨구기 -> 최종 로그 (시간 ,epoch, val acc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import base, creator\n",
    "from deap import tools\n",
    "\n",
    "\n",
    "import random\n",
    "from itertools import repeat\n",
    "from collections import Sequence, OrderedDict\n",
    "\n",
    "# For evaluate function --------------------------\n",
    "import glob\n",
    "from easydict import EasyDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn    # for hardware tunning (cudnn.benchmark = True)\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from thop import profile\n",
    "from thop import clever_format\n",
    "\n",
    "import logging\n",
    "\n",
    "# Gray code package\n",
    "from utils_kyy.utils_graycode import *\n",
    "\n",
    "# custom package in utils_kyy\n",
    "from utils_kyy.utils_graph import load_graph\n",
    "from utils_kyy.models import RWNN\n",
    "from utils_kyy.train_validate import train, validate, train_AMP\n",
    "from utils_kyy.lr_scheduler import LRScheduler\n",
    "from torchsummary import summary\n",
    "# -------------------------------------------------\n",
    "\n",
    "#from apex import amp\n",
    "\n",
    "\n",
    "## For MNIST\n",
    "class ReshapeTransform:\n",
    "    def __init__(self, new_size):\n",
    "        self.new_size = new_size\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return torch.reshape(img, self.new_size)\n",
    "    \n",
    "def evaluate_v2_full_train(individual, args_train, stage_pool_path_list, data_path=None ,channels=109, log_file_name=None):  # individual\n",
    "\n",
    "    \n",
    "    # list 형식의 individual 객체를 input으로 받음   e.g. [0, 4, 17]\n",
    "    # 1) load graph\n",
    "    total_graph_path_list = []\n",
    "    for i in range(3):\n",
    "        total_graph_path_list.append( glob.glob(stage_pool_path_list[i] + '*.yaml') )\n",
    "\n",
    "    graph_name = []\n",
    "\n",
    "    # args_train 셋팅에서 graycode 변환이 true 인지 확인\n",
    "    if args_train.graycode:\n",
    "        ## Decode 해줘야 !\n",
    "        gray_len = len(individual)//3\n",
    "        for i in range(3):\n",
    "            # list to string\n",
    "            tmp = ''\n",
    "            for j in individual[gray_len*i:gray_len*(i+1)]:\n",
    "                tmp += str(j)\n",
    "\n",
    "            # sting to binary to num\n",
    "            graph_name.append(graydecode(int(tmp)))\n",
    "\n",
    "    else :\n",
    "        graph_name = individual\n",
    "\n",
    "    stage_1_graph = load_graph( total_graph_path_list[0][graph_name[0]] )\n",
    "    stage_2_graph = load_graph( total_graph_path_list[1][graph_name[1]] )\n",
    "    stage_3_graph = load_graph( total_graph_path_list[2][graph_name[2]] )\n",
    "    \n",
    "    graphs = EasyDict({'stage_1': stage_1_graph,\n",
    "                       'stage_2': stage_2_graph,\n",
    "                       'stage_3': stage_3_graph\n",
    "                      })\n",
    "\n",
    "    # 2) build RWNN\n",
    "    channels = channels\n",
    "    NN_model = RWNN(net_type='small', graphs=graphs, channels=channels, num_classes=args_train.num_classes, input_channel=args_train.input_dim)\n",
    "    NN_model.cuda()\n",
    "\n",
    "    ###########################\n",
    "    # Flops 계산 - [Debug] nn.DataParallele (for multi-gpu) 적용 전에 확인.\n",
    "    ###########################\n",
    "    input_flops = torch.randn(1, args_train.input_dim, 224, 224).cuda()\n",
    "    flops, params = profile(NN_model, inputs=(input_flops, ), verbose=False)\n",
    "\n",
    "    ## Model summary\n",
    "    #summary(NN_model, input_size=(1, 224, 224))\n",
    "\n",
    "    # 3) Prepare for train### 일단 꺼보자!\n",
    "    #NN_model = nn.DataParallel(NN_model)  # for multi-GPU\n",
    "    #NN_model = nn.DataParallel(NN_model, device_ids=[0,1,2,3])\n",
    "    # define loss function (criterion) and optimizer\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "    optimizer = torch.optim.SGD(NN_model.parameters(), args_train.base_lr,\n",
    "                                momentum=args_train.momentum,\n",
    "                                weight_decay=args_train.weight_decay)\n",
    "    \n",
    "    start_epoch  = 0\n",
    "    best_prec1 = 0    \n",
    "    \n",
    "    cudnn.benchmark = True    # This flag allows you to enable the inbuilt cudnn auto-tuner to find the best algorithm to use for your hardware.  \n",
    "    \n",
    "    ###########################\n",
    "    # Dataset & Dataloader\n",
    "    ###########################\n",
    "\n",
    "    # 이미 다운 받아놨으니 download=False\n",
    "    # 데이터가 없을 경우, 처음에는 download=True 로 설정해놓고 실행해주어야함\n",
    "    \n",
    "    if data_path is None :\n",
    "        data_path = './data'\n",
    "    \n",
    " \n",
    "    if args_train.data == \"CIFAR10\" :\n",
    "\n",
    "        train_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.RandomHorizontalFlip(),  # 추가함\n",
    "                transforms.Resize(224),  # 추가함.  imagenet dataset과 size 맞추기\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # rescale 0 ~ 1 => -1 ~ 1\n",
    "            ])\n",
    "\n",
    "        val_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(224),  # 추가함.  imagenet dataset과 size 맞추기\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # rescale 0 ~ 1 => -1 ~ 1\n",
    "            ])\n",
    "\n",
    "        train_dataset = torchvision.datasets.CIFAR10(root=data_path, train=True,\n",
    "                                                download=True, transform=train_transform)\n",
    "\n",
    "        val_dataset = torchvision.datasets.CIFAR10(root=data_path, train=False,\n",
    "                                               download=True, transform=val_transform)\n",
    "    elif args_train.data == \"MNIST\":\n",
    "\n",
    "        train_transform =  transforms.Compose([\n",
    "                                               transforms.Resize(224),\n",
    "                                                transforms.ToTensor(),  # 추가함.  imagenet dataset과 size 맞추기\n",
    "                                               transforms.Normalize((0.5,), (1.0,)),\n",
    "\n",
    "            ])\n",
    "        val_transform = transforms.Compose([transforms.Resize(224),\n",
    "                                            transforms.ToTensor(),# 추가함.  imagenet dataset과 size 맞추기\n",
    "                                            transforms.Normalize((0.5,), (1.0,))\n",
    "            ])\n",
    "        train_dataset = torchvision.datasets.MNIST(root=data_path, train=True, transform=train_transform, download=True)\n",
    "        val_dataset = torchvision.datasets.MNIST(root=data_path, train=False, transform=val_transform, download=True)\n",
    "        \n",
    "    else :\n",
    "        raise Exception(\"Data Error, Only CIFAR10, MNIST allowed for the moment\")\n",
    "\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args_train.batch_size,\n",
    "                                              shuffle=True, num_workers=args_train.workers)  \n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=args_train.batch_size,\n",
    "                                             shuffle=False, num_workers=args_train.workers)    \n",
    "    \n",
    "    ###########################\n",
    "    # Train\n",
    "    ###########################\n",
    "    niters = len(train_loader)\n",
    "    niters = 1\n",
    "\n",
    "    lr_scheduler = LRScheduler(optimizer, niters, args_train)  # (default) args.step = [30, 60, 90], args.decay_factor = 0.1, args.power = 2.0    \n",
    "    cnt = 0 \n",
    "    epoch = 0\n",
    "    \n",
    "    while True :\n",
    "        \n",
    "        # train for one epoch\n",
    "        train(train_loader, NN_model, criterion, optimizer, lr_scheduler, epoch, args_train.print_freq, log_file_name)\n",
    "\n",
    "        # evaluate on validation set\n",
    "        prec1 = validate(val_loader, NN_model, criterion, epoch, log_file_name)\n",
    "        \n",
    "        epoch += 1\n",
    "\n",
    "        # remember best prec@1 and save checkpoint\n",
    "#         is_best = prec1 > best_prec1\n",
    "        if prec1 > best_prec1 :\n",
    "            best_prec1 = prec1\n",
    "            cnt = 0\n",
    "        else :\n",
    "            cnt += 1\n",
    "        \n",
    "        if epoch == 2 :\n",
    "            break\n",
    "\n",
    "    return (-best_prec1, flops), epoch  # Min (-val_accuracy, flops) 이므로 val_accuracy(top1)에 - 붙여서 return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "from easydict import EasyDict\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "from deap import tools\n",
    "from collections import OrderedDict\n",
    "from pprint import pprint\n",
    "import json\n",
    "import torch\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "from utils_kyy.utils_graph import make_random_graph_v2\n",
    "from utils_kyy.create_toolbox import create_toolbox_for_NSGA_RWNN, evaluate_v2\n",
    "\n",
    "\n",
    "import argparse\n",
    "import random\n",
    "\n",
    "\n",
    "class full_train:\n",
    "    def __init__(self, json_file):\n",
    "        self.root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "        self.param_dir = os.path.join(self.root + '/parameters/', json_file)\n",
    "        f = open(self.param_dir)\n",
    "        params = json.load(f)\n",
    "        pprint(params)\n",
    "        self.name = params['NAME']\n",
    "\n",
    "        ## toolbox params\n",
    "        self.args_train = EasyDict(params['ARGS_TRAIN'])\n",
    "        self.data_path = params['DATA_PATH']\n",
    "        self.run_code = params['RUN_CODE']\n",
    "        self.stage_pool_path = '../graph_pool' + '/' + self.run_code + '_' + 'experiment_1' + '/'\n",
    "        self.stage_pool_path_list = []\n",
    "        for i in range(1, 4):\n",
    "            stage_pool_path_i = self.stage_pool_path + str(i) + '/'  # eg. [graph_pool/run_code_name/1/, ... ]\n",
    "            self.stage_pool_path_list.append(stage_pool_path_i)\n",
    "        \n",
    "        self.log_path = '../logs/' + self.run_code + '_' + self.name + '/'\n",
    "        # self.log_file_name : Initialize 부터 GA 진행상황 등 코드 전체에 대한 logging\n",
    "        self.log_file_name = self.log_path + 'logging.log'\n",
    "        # self.train_log_file_name : fitness (= flops, val_accuracy). 즉 GA history 를 저장 후, 나중에 사용하기 위한 logging.\n",
    "        self.train_log_file_name = self.log_path + 'train_logging.log'\n",
    "        \n",
    "        if not os.path.exists(self.stage_pool_path):\n",
    "            os.makedirs(self.stage_pool_path)\n",
    "            for i in range(3):\n",
    "                os.makedirs(self.stage_pool_path_list[i])\n",
    "                \n",
    "        if not os.path.isdir(self.log_path):\n",
    "            os.makedirs(self.log_path)\n",
    "            \n",
    "        logging.basicConfig(filename=self.log_file_name, level=logging.INFO)\n",
    "        logging.info('[Start] Rwns_train class is initialized.')        \n",
    "        logging.info('Start to write log.')\n",
    "            \n",
    "        self.num_graph = params['NUM_GRAPH']\n",
    "        \n",
    "        \n",
    "        ## Temperary\n",
    "        self.models = [[1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1],\n",
    "       [1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1],\n",
    "       [1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1],\n",
    "       [1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1],\n",
    "       [1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1],\n",
    "       [1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1],\n",
    "       [1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0]]\n",
    "        \n",
    "        self.random_models = [[0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1],\n",
    "       [1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0],\n",
    "       [1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0],\n",
    "       [0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0],\n",
    "       [0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0],\n",
    "       [1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0],\n",
    "       [1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0]]\n",
    "       \n",
    "        #self.random_models = \n",
    "        \n",
    "\n",
    "        ## logs\n",
    "        self.log = OrderedDict()\n",
    "        self.log['hp'] = self.args_train\n",
    "        self.train_log = OrderedDict()\n",
    "        \n",
    "        ## 기존 train_log 불러와서 이어서 train하기\n",
    "        self.TRAIN_FROM_LOGS = params['TRAIN_FROM_LOGS']\n",
    "        self.REAL_TRAIN_LOG_PATH = params['REAL_TRAIN_LOG_PATH']\n",
    "        \n",
    "        \n",
    "        \n",
    "    def train(self,mode=0):\n",
    "        \n",
    "        # mode = 0 : GA, 1: random\n",
    "        inds = self.models\n",
    "        if mode == 1 : inds = self.random_models\n",
    "        \n",
    "        \n",
    "    ###################################\n",
    "    # 1. Initialize the population.  (toolbox.population은 creator.Individual n개를 담은 list를 반환. (=> population)\n",
    "    ###################################\n",
    "        now = datetime.datetime.now()\n",
    "        now_str = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        ## ind는 gray code로 되어 있다\n",
    "        ### 모델 가져오기 --> evaluate 함수\n",
    "        ##  모델 트레이닝\n",
    "\n",
    "\n",
    "        ### inds 만들기\n",
    "        # 떨궈진 파일 파싱하기? \n",
    "        inds = self.models\n",
    "\n",
    "        if self.TRAIN_FROM_LOGS == False:\n",
    "\n",
    "            for idx, ind in enumerate(inds):\n",
    "\n",
    "                logging.info(\"Start Model Training \" + now_str + \" model \" + str(idx))\n",
    "                init_start_time = time.time()\n",
    "                model_dict =  {}\n",
    "                fitness, epoch = evaluate_v2_full_train(ind, args_train=self.args_train,\n",
    "                                                     stage_pool_path_list=self.stage_pool_path_list,\n",
    "                                                     data_path=self.data_path,\n",
    "                                                     log_file_name=self.log_file_name)\n",
    "\n",
    "                now_str = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "                logging.info(\"Initialion is finished at \" + now_str)\n",
    "\n",
    "\n",
    "                end_time = time.time()\n",
    "                model_dict['model_id'] = ind \n",
    "                model_dict['fitness'] = fitness\n",
    "                model_dict['time'] = end_time - init_start_time\n",
    "                model_dict['epoch'] = epoch\n",
    "\n",
    "\n",
    "                ## log 기록 - initialize (= 0th generation)\n",
    "                self.train_log[str(idx)] = model_dict\n",
    "                self.save_log()\n",
    "\n",
    "\n",
    "\n",
    "        # train_log 읽어와서 중간부터 이어서 train 하는 경우\n",
    "        # [Reference] Seeding a population => https://deap.readthedocs.io/en/master/tutorials/basic/part1.html\n",
    "        elif self.TRAIN_FROM_LOGS == True:\n",
    "            print(\"################# [KYY-check] Read train_log from the middle #################\")\n",
    "            logging.info(\"################# [KYY-check] Read train_log from the middle #################\")\n",
    "\n",
    "            # train_log 읽어오기\n",
    "            with open(self.REAL_TRAIN_LOG_PATH) as train_log_json_file:\n",
    "                data = json.load(train_log_json_file)  # hp(=hyperparameter), train_log 있음\n",
    "\n",
    "            train_log_past = data['train_log']\n",
    "            niter = len(train_log_past)  # 기록 상 총 init 횟수\n",
    "\n",
    "            start_gen = niter  # niter = 11 이면, log 상에 0 ~ 10번까지 기록되어있는 것.\n",
    "\n",
    "            # self.train_log 에 읽어온 로그 넣어놓기 (OrderedDict())\n",
    "            for i in range(niter):\n",
    "                self.train_log[str(i)] = train_log_past[str(i)]\n",
    "\n",
    "\n",
    "            for idx in range(niter, len(inds)):\n",
    "\n",
    "                ind = inds[idx]\n",
    "\n",
    "                logging.info(\"Start Model Training \" + now_str + \" model \" + idx)\n",
    "                init_start_time = time.time()\n",
    "                model_dict =  {}\n",
    "                fitness, epoch = evaluate_v2_full_train(ind, args_train=self.args_train,\n",
    "                                                     stage_pool_path_list=self.stage_pool_path_list,\n",
    "                                                     data_path=self.data_path,\n",
    "                                                     log_file_name=self.log_file_name)\n",
    "\n",
    "                now_str = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "                logging.info(\"Initialion is finished at \" + now_str)\n",
    "\n",
    "\n",
    "                end_time = time.time()\n",
    "                model_dict['model_id'] = ind \n",
    "                model_dict['fitness'] = fitness\n",
    "                model_dict['time'] = end_time - init_start_time\n",
    "                model_dict['epoch'] = epoch\n",
    "\n",
    "\n",
    "                ## log 기록 - initialize (= 0th generation)\n",
    "                self.train_log[str(idx)] = model_dict\n",
    "                self.save_log()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ## Save Log\n",
    "    def save_log(self):\n",
    "        ## 필요한 log 추후 정리하여 추가 \n",
    "        self.log['train_log'] = self.train_log\n",
    "\n",
    "        with open(self.train_log_file_name, 'w', encoding='utf-8') as make_file:\n",
    "            json.dump(self.log, make_file, ensure_ascii=False, indent='\\t')\n",
    "\n",
    "            \n",
    "        \n",
    "# if __name__ == \"__main__\":\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument('--params', type=str, help='Parameter Json file')\n",
    "    \n",
    "#     args = parser.parse_args()\n",
    "    \n",
    "#     trainer = full_train(json_file=args.params)\n",
    "\n",
    "#     trainer.train()\n",
    "#     trainer.save_log()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ARGS_TRAIN': {'base_lr': 0.2,\n",
      "                'batch_size': 32,\n",
      "                'data': 'CIFAR10',\n",
      "                'epochs': 5,\n",
      "                'graycode': True,\n",
      "                'input_dim': 3,\n",
      "                'lr_mode': 'cosine',\n",
      "                'momentum': 0.9,\n",
      "                'num_classes': 10,\n",
      "                'print_freq': 100,\n",
      "                'targetlr': 0.0,\n",
      "                'warmup_epochs': 0,\n",
      "                'warmup_lr': 0.0,\n",
      "                'warmup_mode': 'linear',\n",
      "                'weight_decay': 5e-05,\n",
      "                'workers': 4},\n",
      " 'DATA_PATH': 'D:/data/cifar10/',\n",
      " 'NAME': 'full_train',\n",
      " 'NUM_GRAPH': 128,\n",
      " 'REAL_TRAIN_LOG_PATH': '/root/data/basic_model/logs/__New_main_experiment_1_to13gen/train_logging.log',\n",
      " 'RUN_CODE': 'New_main',\n",
      " 'TRAIN_FROM_LOGS': False}\n"
     ]
    }
   ],
   "source": [
    "trainer = full_train(json_file='full_train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\t - Epoch: [0][0/1563]\tTime 6.871 (6.871)\tLoss 2.3372 (2.3372)\tPrec@1 3.125 (3.125)\tPrec@5 37.500 (37.500)\n",
      "\t - Epoch: [0][100/1563]\tTime 0.871 (0.847)\tLoss 2.2453 (2.4310)\tPrec@1 9.375 (13.181)\tPrec@5 53.125 (57.426)\n",
      "\t - Epoch: [0][200/1563]\tTime 0.730 (0.813)\tLoss 2.1650 (2.2854)\tPrec@1 15.625 (15.967)\tPrec@5 78.125 (65.205)\n",
      "\t - Epoch: [0][300/1563]\tTime 0.722 (0.801)\tLoss 2.0291 (2.2044)\tPrec@1 28.125 (18.272)\tPrec@5 71.875 (68.978)\n",
      "\t - Epoch: [0][400/1563]\tTime 0.729 (0.793)\tLoss 1.7214 (2.1513)\tPrec@1 46.875 (20.433)\tPrec@5 84.375 (71.626)\n",
      "\t - Epoch: [0][500/1563]\tTime 0.743 (0.792)\tLoss 1.8915 (2.1148)\tPrec@1 21.875 (21.850)\tPrec@5 87.500 (73.428)\n",
      "\t - Epoch: [0][600/1563]\tTime 0.798 (0.792)\tLoss 1.7782 (2.0791)\tPrec@1 28.125 (23.102)\tPrec@5 81.250 (75.192)\n",
      "\t - Epoch: [0][700/1563]\tTime 0.893 (0.796)\tLoss 1.8582 (2.0521)\tPrec@1 31.250 (24.055)\tPrec@5 90.625 (76.306)\n",
      "\t - Epoch: [0][800/1563]\tTime 0.877 (0.797)\tLoss 1.6892 (2.0239)\tPrec@1 34.375 (25.074)\tPrec@5 87.500 (77.415)\n",
      "\t - Epoch: [0][900/1563]\tTime 0.880 (0.796)\tLoss 1.7378 (1.9975)\tPrec@1 40.625 (25.957)\tPrec@5 87.500 (78.344)\n",
      "\t - Epoch: [0][1000/1563]\tTime 0.736 (0.796)\tLoss 1.6814 (1.9765)\tPrec@1 37.500 (26.823)\tPrec@5 90.625 (79.046)\n",
      "\t - Epoch: [0][1100/1563]\tTime 0.731 (0.795)\tLoss 1.6277 (1.9553)\tPrec@1 43.750 (27.600)\tPrec@5 81.250 (79.712)\n",
      "\t - Epoch: [0][1200/1563]\tTime 0.727 (0.795)\tLoss 1.6392 (1.9361)\tPrec@1 37.500 (28.338)\tPrec@5 93.750 (80.355)\n",
      "\t - Epoch: [0][1300/1563]\tTime 0.726 (0.793)\tLoss 1.4903 (1.9195)\tPrec@1 50.000 (28.975)\tPrec@5 93.750 (80.856)\n",
      "\t - Epoch: [0][1400/1563]\tTime 0.997 (0.794)\tLoss 1.8693 (1.9043)\tPrec@1 37.500 (29.593)\tPrec@5 78.125 (81.359)\n",
      "\t - Epoch: [0][1500/1563]\tTime 0.745 (0.794)\tLoss 1.4194 (1.8877)\tPrec@1 43.750 (30.267)\tPrec@5 96.875 (81.858)\n",
      "##### Validation_time 60.646 Prec@1 38.420 Prec@5 89.610 #####\n",
      "\t - Epoch: [1][0/1563]\tTime 6.893 (6.893)\tLoss 1.3716 (1.3716)\tPrec@1 50.000 (50.000)\tPrec@5 96.875 (96.875)\n",
      "\t - Epoch: [1][100/1563]\tTime 0.934 (0.845)\tLoss 1.6904 (1.5887)\tPrec@1 34.375 (41.058)\tPrec@5 90.625 (90.161)\n",
      "\t - Epoch: [1][200/1563]\tTime 0.740 (0.821)\tLoss 1.2010 (1.5978)\tPrec@1 62.500 (41.200)\tPrec@5 93.750 (90.050)\n",
      "\t - Epoch: [1][300/1563]\tTime 0.733 (0.815)\tLoss 1.3784 (1.5834)\tPrec@1 40.625 (41.591)\tPrec@5 100.000 (90.012)\n",
      "\t - Epoch: [1][400/1563]\tTime 0.744 (0.806)\tLoss 1.6112 (1.5843)\tPrec@1 40.625 (41.576)\tPrec@5 93.750 (90.173)\n",
      "\t - Epoch: [1][500/1563]\tTime 0.735 (0.801)\tLoss 1.5443 (1.5745)\tPrec@1 40.625 (42.041)\tPrec@5 87.500 (90.213)\n",
      "\t - Epoch: [1][600/1563]\tTime 0.951 (0.799)\tLoss 1.2068 (1.5664)\tPrec@1 56.250 (42.533)\tPrec@5 96.875 (90.391)\n",
      "\t - Epoch: [1][700/1563]\tTime 0.868 (0.797)\tLoss 1.3470 (1.5632)\tPrec@1 43.750 (42.609)\tPrec@5 100.000 (90.465)\n",
      "\t - Epoch: [1][800/1563]\tTime 0.754 (0.795)\tLoss 1.3039 (1.5576)\tPrec@1 56.250 (42.880)\tPrec@5 93.750 (90.477)\n",
      "\t - Epoch: [1][900/1563]\tTime 0.796 (0.794)\tLoss 1.5777 (1.5535)\tPrec@1 34.375 (43.088)\tPrec@5 93.750 (90.524)\n",
      "\t - Epoch: [1][1000/1563]\tTime 0.739 (0.792)\tLoss 1.2444 (1.5427)\tPrec@1 56.250 (43.438)\tPrec@5 87.500 (90.781)\n",
      "\t - Epoch: [1][1100/1563]\tTime 0.807 (0.791)\tLoss 1.6787 (1.5355)\tPrec@1 43.750 (43.639)\tPrec@5 78.125 (90.906)\n",
      "\t - Epoch: [1][1200/1563]\tTime 0.742 (0.790)\tLoss 1.5549 (1.5293)\tPrec@1 40.625 (43.898)\tPrec@5 90.625 (91.013)\n",
      "\t - Epoch: [1][1300/1563]\tTime 0.952 (0.791)\tLoss 1.3263 (1.5212)\tPrec@1 40.625 (44.276)\tPrec@5 93.750 (91.134)\n",
      "\t - Epoch: [1][1400/1563]\tTime 0.875 (0.791)\tLoss 1.1744 (1.5127)\tPrec@1 46.875 (44.573)\tPrec@5 96.875 (91.287)\n",
      "\t - Epoch: [1][1500/1563]\tTime 0.727 (0.790)\tLoss 1.4196 (1.5060)\tPrec@1 56.250 (44.839)\tPrec@5 90.625 (91.375)\n",
      "##### Validation_time 58.551 Prec@1 45.570 Prec@5 91.980 #####\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\t - Epoch: [0][0/1563]\tTime 6.929 (6.929)\tLoss 2.2917 (2.2917)\tPrec@1 9.375 (9.375)\tPrec@5 40.625 (40.625)\n",
      "\t - Epoch: [0][100/1563]\tTime 0.909 (0.941)\tLoss 2.3092 (2.5744)\tPrec@1 15.625 (11.696)\tPrec@5 62.500 (51.856)\n",
      "\t - Epoch: [0][200/1563]\tTime 0.829 (0.907)\tLoss 2.0940 (2.3926)\tPrec@1 21.875 (14.521)\tPrec@5 75.000 (59.375)\n",
      "\t - Epoch: [0][300/1563]\tTime 1.141 (0.900)\tLoss 2.1809 (2.2907)\tPrec@1 21.875 (16.487)\tPrec@5 65.625 (64.410)\n",
      "\t - Epoch: [0][400/1563]\tTime 0.810 (0.895)\tLoss 1.8102 (2.2324)\tPrec@1 25.000 (17.994)\tPrec@5 84.375 (67.433)\n",
      "\t - Epoch: [0][500/1563]\tTime 0.823 (0.894)\tLoss 2.2007 (2.1856)\tPrec@1 15.625 (19.336)\tPrec@5 84.375 (69.667)\n",
      "\t - Epoch: [0][600/1563]\tTime 0.817 (0.892)\tLoss 2.0817 (2.1512)\tPrec@1 12.500 (20.372)\tPrec@5 68.750 (71.402)\n",
      "\t - Epoch: [0][700/1563]\tTime 0.819 (0.888)\tLoss 1.9795 (2.1191)\tPrec@1 28.125 (21.585)\tPrec@5 75.000 (72.878)\n",
      "\t - Epoch: [0][800/1563]\tTime 0.811 (0.888)\tLoss 1.7719 (2.0888)\tPrec@1 34.375 (22.776)\tPrec@5 87.500 (74.157)\n",
      "\t - Epoch: [0][900/1563]\tTime 0.818 (0.885)\tLoss 1.7282 (2.0616)\tPrec@1 34.375 (23.790)\tPrec@5 84.375 (75.246)\n",
      "\t - Epoch: [0][1000/1563]\tTime 0.821 (0.884)\tLoss 1.9067 (2.0373)\tPrec@1 31.250 (24.713)\tPrec@5 75.000 (76.202)\n",
      "\t - Epoch: [0][1100/1563]\tTime 0.824 (0.883)\tLoss 1.7663 (2.0177)\tPrec@1 34.375 (25.397)\tPrec@5 84.375 (76.987)\n",
      "\t - Epoch: [0][1200/1563]\tTime 0.821 (0.883)\tLoss 1.7201 (1.9997)\tPrec@1 25.000 (26.098)\tPrec@5 90.625 (77.685)\n",
      "\t - Epoch: [0][1300/1563]\tTime 0.819 (0.884)\tLoss 1.6999 (1.9841)\tPrec@1 40.625 (26.667)\tPrec@5 87.500 (78.298)\n",
      "\t - Epoch: [0][1400/1563]\tTime 0.816 (0.883)\tLoss 1.8001 (1.9686)\tPrec@1 34.375 (27.188)\tPrec@5 87.500 (78.888)\n",
      "\t - Epoch: [0][1500/1563]\tTime 0.897 (0.883)\tLoss 1.4971 (1.9551)\tPrec@1 50.000 (27.671)\tPrec@5 96.875 (79.405)\n",
      "##### Validation_time 66.549 Prec@1 28.840 Prec@5 83.390 #####\n",
      "\t - Epoch: [1][0/1563]\tTime 6.881 (6.881)\tLoss 2.2826 (2.2826)\tPrec@1 25.000 (25.000)\tPrec@5 81.250 (81.250)\n",
      "\t - Epoch: [1][100/1563]\tTime 0.987 (0.944)\tLoss 1.5710 (1.7454)\tPrec@1 43.750 (35.303)\tPrec@5 90.625 (86.912)\n",
      "\t - Epoch: [1][200/1563]\tTime 0.822 (0.927)\tLoss 1.6292 (1.7321)\tPrec@1 37.500 (36.039)\tPrec@5 90.625 (86.707)\n",
      "\t - Epoch: [1][300/1563]\tTime 0.827 (0.909)\tLoss 1.6864 (1.7046)\tPrec@1 40.625 (37.116)\tPrec@5 87.500 (87.407)\n",
      "\t - Epoch: [1][400/1563]\tTime 0.932 (0.902)\tLoss 1.4177 (1.6845)\tPrec@1 46.875 (37.718)\tPrec@5 87.500 (87.952)\n",
      "\t - Epoch: [1][500/1563]\tTime 0.817 (0.900)\tLoss 1.8144 (1.6767)\tPrec@1 34.375 (38.093)\tPrec@5 81.250 (88.211)\n",
      "\t - Epoch: [1][600/1563]\tTime 0.819 (0.897)\tLoss 1.4897 (1.6674)\tPrec@1 50.000 (38.524)\tPrec@5 81.250 (88.374)\n",
      "\t - Epoch: [1][700/1563]\tTime 0.921 (0.895)\tLoss 1.8043 (1.6614)\tPrec@1 31.250 (38.828)\tPrec@5 90.625 (88.427)\n",
      "\t - Epoch: [1][800/1563]\tTime 0.815 (0.894)\tLoss 1.2432 (1.6525)\tPrec@1 59.375 (39.111)\tPrec@5 96.875 (88.624)\n",
      "\t - Epoch: [1][900/1563]\tTime 0.825 (0.894)\tLoss 1.4411 (1.6442)\tPrec@1 40.625 (39.491)\tPrec@5 90.625 (88.811)\n",
      "\t - Epoch: [1][1000/1563]\tTime 0.813 (0.890)\tLoss 1.4743 (1.6376)\tPrec@1 53.125 (39.751)\tPrec@5 90.625 (88.880)\n",
      "\t - Epoch: [1][1100/1563]\tTime 0.819 (0.892)\tLoss 1.4073 (1.6250)\tPrec@1 43.750 (40.239)\tPrec@5 96.875 (89.160)\n",
      "\t - Epoch: [1][1200/1563]\tTime 0.809 (0.891)\tLoss 1.7408 (1.6210)\tPrec@1 40.625 (40.396)\tPrec@5 84.375 (89.290)\n",
      "\t - Epoch: [1][1300/1563]\tTime 0.913 (0.891)\tLoss 1.0953 (1.6097)\tPrec@1 59.375 (40.731)\tPrec@5 96.875 (89.566)\n",
      "\t - Epoch: [1][1400/1563]\tTime 0.909 (0.889)\tLoss 1.2636 (1.6016)\tPrec@1 56.250 (41.024)\tPrec@5 96.875 (89.679)\n",
      "\t - Epoch: [1][1500/1563]\tTime 0.910 (0.888)\tLoss 1.4279 (1.5901)\tPrec@1 37.500 (41.504)\tPrec@5 93.750 (89.851)\n",
      "##### Validation_time 67.809 Prec@1 43.960 Prec@5 92.100 #####\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\t - Epoch: [0][0/1563]\tTime 6.406 (6.406)\tLoss 2.3109 (2.3109)\tPrec@1 9.375 (9.375)\tPrec@5 46.875 (46.875)\n",
      "\t - Epoch: [0][100/1563]\tTime 0.479 (0.570)\tLoss 2.0216 (2.4376)\tPrec@1 18.750 (13.088)\tPrec@5 75.000 (59.623)\n",
      "\t - Epoch: [0][200/1563]\tTime 0.471 (0.534)\tLoss 1.9705 (2.2688)\tPrec@1 31.250 (17.055)\tPrec@5 75.000 (66.760)\n",
      "\t - Epoch: [0][300/1563]\tTime 0.483 (0.524)\tLoss 1.8361 (2.1686)\tPrec@1 21.875 (19.601)\tPrec@5 87.500 (71.366)\n",
      "\t - Epoch: [0][400/1563]\tTime 0.485 (0.518)\tLoss 1.9207 (2.1137)\tPrec@1 21.875 (20.924)\tPrec@5 84.375 (74.041)\n",
      "\t - Epoch: [0][500/1563]\tTime 0.477 (0.516)\tLoss 1.8987 (2.0757)\tPrec@1 34.375 (21.719)\tPrec@5 81.250 (75.686)\n",
      "\t - Epoch: [0][600/1563]\tTime 0.477 (0.514)\tLoss 1.8128 (2.0438)\tPrec@1 34.375 (22.832)\tPrec@5 87.500 (76.976)\n",
      "\t - Epoch: [0][700/1563]\tTime 0.478 (0.512)\tLoss 1.9868 (2.0186)\tPrec@1 34.375 (23.886)\tPrec@5 78.125 (77.880)\n",
      "\t - Epoch: [0][800/1563]\tTime 0.479 (0.511)\tLoss 1.5519 (1.9937)\tPrec@1 37.500 (24.754)\tPrec@5 96.875 (78.792)\n",
      "\t - Epoch: [0][900/1563]\tTime 0.480 (0.511)\tLoss 1.7452 (1.9678)\tPrec@1 40.625 (25.919)\tPrec@5 84.375 (79.575)\n",
      "\t - Epoch: [0][1000/1563]\tTime 0.477 (0.510)\tLoss 1.9692 (1.9466)\tPrec@1 15.625 (26.795)\tPrec@5 90.625 (80.229)\n",
      "\t - Epoch: [0][1100/1563]\tTime 0.488 (0.510)\tLoss 1.7464 (1.9249)\tPrec@1 28.125 (27.662)\tPrec@5 87.500 (80.907)\n",
      "\t - Epoch: [0][1200/1563]\tTime 0.479 (0.510)\tLoss 1.5740 (1.9058)\tPrec@1 46.875 (28.440)\tPrec@5 96.875 (81.601)\n",
      "\t - Epoch: [0][1300/1563]\tTime 0.507 (0.510)\tLoss 1.6502 (1.8882)\tPrec@1 34.375 (29.230)\tPrec@5 90.625 (82.146)\n",
      "\t - Epoch: [0][1400/1563]\tTime 0.475 (0.511)\tLoss 1.5679 (1.8675)\tPrec@1 43.750 (29.927)\tPrec@5 90.625 (82.749)\n",
      "\t - Epoch: [0][1500/1563]\tTime 0.518 (0.511)\tLoss 1.6265 (1.8489)\tPrec@1 40.625 (30.617)\tPrec@5 87.500 (83.317)\n",
      "##### Validation_time 41.213 Prec@1 42.890 Prec@5 92.230 #####\n",
      "\t - Epoch: [1][0/1563]\tTime 6.617 (6.617)\tLoss 2.1536 (2.1536)\tPrec@1 31.250 (31.250)\tPrec@5 81.250 (81.250)\n",
      "\t - Epoch: [1][100/1563]\tTime 0.481 (0.576)\tLoss 1.8090 (1.5230)\tPrec@1 34.375 (43.812)\tPrec@5 81.250 (91.739)\n",
      "\t - Epoch: [1][200/1563]\tTime 0.480 (0.538)\tLoss 1.5959 (1.5162)\tPrec@1 34.375 (43.999)\tPrec@5 87.500 (91.760)\n",
      "\t - Epoch: [1][300/1563]\tTime 0.633 (0.532)\tLoss 1.2752 (1.4928)\tPrec@1 56.250 (45.037)\tPrec@5 90.625 (92.027)\n",
      "\t - Epoch: [1][400/1563]\tTime 0.522 (0.524)\tLoss 1.5753 (1.4860)\tPrec@1 46.875 (45.293)\tPrec@5 93.750 (92.043)\n",
      "\t - Epoch: [1][500/1563]\tTime 0.530 (0.520)\tLoss 1.0796 (1.4767)\tPrec@1 68.750 (45.659)\tPrec@5 96.875 (92.234)\n",
      "\t - Epoch: [1][600/1563]\tTime 0.479 (0.519)\tLoss 1.2422 (1.4597)\tPrec@1 59.375 (46.360)\tPrec@5 93.750 (92.486)\n",
      "\t - Epoch: [1][700/1563]\tTime 0.591 (0.517)\tLoss 1.1644 (1.4442)\tPrec@1 43.750 (46.960)\tPrec@5 100.000 (92.613)\n",
      "\t - Epoch: [1][800/1563]\tTime 0.480 (0.516)\tLoss 1.1384 (1.4298)\tPrec@1 68.750 (47.511)\tPrec@5 100.000 (92.814)\n",
      "\t - Epoch: [1][900/1563]\tTime 0.635 (0.515)\tLoss 1.1548 (1.4152)\tPrec@1 56.250 (48.137)\tPrec@5 90.625 (92.956)\n",
      "\t - Epoch: [1][1000/1563]\tTime 0.524 (0.513)\tLoss 1.2082 (1.3951)\tPrec@1 56.250 (48.848)\tPrec@5 100.000 (93.279)\n",
      "\t - Epoch: [1][1100/1563]\tTime 0.479 (0.513)\tLoss 1.5499 (1.3808)\tPrec@1 34.375 (49.461)\tPrec@5 87.500 (93.449)\n",
      "\t - Epoch: [1][1200/1563]\tTime 0.477 (0.512)\tLoss 1.1362 (1.3683)\tPrec@1 59.375 (49.969)\tPrec@5 100.000 (93.607)\n",
      "\t - Epoch: [1][1300/1563]\tTime 0.480 (0.512)\tLoss 1.3128 (1.3557)\tPrec@1 62.500 (50.461)\tPrec@5 90.625 (93.740)\n",
      "\t - Epoch: [1][1400/1563]\tTime 0.533 (0.512)\tLoss 0.9788 (1.3416)\tPrec@1 59.375 (51.002)\tPrec@5 93.750 (93.844)\n",
      "\t - Epoch: [1][1500/1563]\tTime 0.480 (0.511)\tLoss 0.9841 (1.3291)\tPrec@1 71.875 (51.543)\tPrec@5 96.875 (93.971)\n",
      "##### Validation_time 38.527 Prec@1 60.810 Prec@5 95.900 #####\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\t - Epoch: [0][0/1563]\tTime 6.577 (6.577)\tLoss 2.3243 (2.3243)\tPrec@1 3.125 (3.125)\tPrec@5 43.750 (43.750)\n",
      "\t - Epoch: [0][100/1563]\tTime 0.592 (0.686)\tLoss 2.1373 (2.4980)\tPrec@1 15.625 (12.036)\tPrec@5 65.625 (54.672)\n",
      "\t - Epoch: [0][200/1563]\tTime 0.678 (0.661)\tLoss 2.0228 (2.3186)\tPrec@1 31.250 (16.418)\tPrec@5 81.250 (63.122)\n",
      "\t - Epoch: [0][300/1563]\tTime 0.574 (0.645)\tLoss 2.0396 (2.2323)\tPrec@1 34.375 (18.729)\tPrec@5 78.125 (67.598)\n",
      "\t - Epoch: [0][400/1563]\tTime 0.597 (0.639)\tLoss 1.9731 (2.1703)\tPrec@1 28.125 (20.815)\tPrec@5 84.375 (70.355)\n",
      "\t - Epoch: [0][500/1563]\tTime 0.679 (0.638)\tLoss 1.7169 (2.1211)\tPrec@1 37.500 (22.218)\tPrec@5 87.500 (72.499)\n",
      "\t - Epoch: [0][600/1563]\tTime 0.589 (0.637)\tLoss 1.7559 (2.0848)\tPrec@1 40.625 (23.445)\tPrec@5 84.375 (73.996)\n",
      "\t - Epoch: [0][700/1563]\tTime 0.674 (0.637)\tLoss 1.7955 (2.0496)\tPrec@1 31.250 (24.692)\tPrec@5 90.625 (75.392)\n",
      "\t - Epoch: [0][800/1563]\tTime 0.588 (0.634)\tLoss 1.5322 (2.0175)\tPrec@1 37.500 (25.655)\tPrec@5 90.625 (76.654)\n",
      "\t - Epoch: [0][900/1563]\tTime 0.681 (0.632)\tLoss 1.8596 (1.9934)\tPrec@1 34.375 (26.613)\tPrec@5 87.500 (77.643)\n",
      "\t - Epoch: [0][1000/1563]\tTime 0.570 (0.631)\tLoss 1.7071 (1.9718)\tPrec@1 31.250 (27.394)\tPrec@5 87.500 (78.468)\n",
      "\t - Epoch: [0][1100/1563]\tTime 0.593 (0.630)\tLoss 1.6242 (1.9497)\tPrec@1 37.500 (28.335)\tPrec@5 100.000 (79.238)\n",
      "\t - Epoch: [0][1200/1563]\tTime 0.616 (0.630)\tLoss 1.3701 (1.9293)\tPrec@1 50.000 (29.184)\tPrec@5 100.000 (79.993)\n",
      "\t - Epoch: [0][1300/1563]\tTime 0.594 (0.629)\tLoss 1.5640 (1.9070)\tPrec@1 34.375 (29.924)\tPrec@5 93.750 (80.714)\n",
      "\t - Epoch: [0][1400/1563]\tTime 0.575 (0.628)\tLoss 1.8439 (1.8903)\tPrec@1 40.625 (30.485)\tPrec@5 75.000 (81.272)\n",
      "\t - Epoch: [0][1500/1563]\tTime 0.742 (0.628)\tLoss 1.3718 (1.8714)\tPrec@1 50.000 (31.194)\tPrec@5 93.750 (81.833)\n",
      "##### Validation_time 50.630 Prec@1 36.830 Prec@5 87.660 #####\n",
      "\t - Epoch: [1][0/1563]\tTime 8.122 (8.122)\tLoss 1.5965 (1.5965)\tPrec@1 37.500 (37.500)\tPrec@5 87.500 (87.500)\n",
      "\t - Epoch: [1][100/1563]\tTime 0.609 (0.706)\tLoss 1.7288 (1.5800)\tPrec@1 34.375 (42.543)\tPrec@5 81.250 (89.851)\n",
      "\t - Epoch: [1][200/1563]\tTime 0.567 (0.668)\tLoss 1.6133 (1.5723)\tPrec@1 37.500 (42.817)\tPrec@5 87.500 (89.801)\n",
      "\t - Epoch: [1][300/1563]\tTime 0.627 (0.652)\tLoss 1.2455 (1.5574)\tPrec@1 50.000 (43.407)\tPrec@5 96.875 (90.345)\n",
      "\t - Epoch: [1][400/1563]\tTime 0.658 (0.641)\tLoss 1.2531 (1.5385)\tPrec@1 62.500 (44.062)\tPrec@5 90.625 (90.742)\n",
      "\t - Epoch: [1][500/1563]\tTime 0.564 (0.634)\tLoss 1.6599 (1.5298)\tPrec@1 46.875 (44.261)\tPrec@5 87.500 (91.155)\n",
      "\t - Epoch: [1][600/1563]\tTime 0.606 (0.631)\tLoss 1.5694 (1.5235)\tPrec@1 37.500 (44.577)\tPrec@5 90.625 (91.192)\n",
      "\t - Epoch: [1][700/1563]\tTime 0.591 (0.628)\tLoss 1.1775 (1.5084)\tPrec@1 59.375 (45.007)\tPrec@5 93.750 (91.485)\n",
      "\t - Epoch: [1][800/1563]\tTime 0.628 (0.625)\tLoss 1.5964 (1.5022)\tPrec@1 34.375 (45.147)\tPrec@5 96.875 (91.515)\n",
      "\t - Epoch: [1][900/1563]\tTime 0.618 (0.625)\tLoss 1.1153 (1.4862)\tPrec@1 56.250 (45.755)\tPrec@5 93.750 (91.724)\n",
      "\t - Epoch: [1][1000/1563]\tTime 0.555 (0.623)\tLoss 1.0959 (1.4695)\tPrec@1 65.625 (46.357)\tPrec@5 93.750 (91.971)\n",
      "\t - Epoch: [1][1100/1563]\tTime 0.572 (0.620)\tLoss 1.4345 (1.4531)\tPrec@1 53.125 (47.011)\tPrec@5 100.000 (92.175)\n",
      "\t - Epoch: [1][1200/1563]\tTime 0.566 (0.617)\tLoss 1.4884 (1.4364)\tPrec@1 50.000 (47.687)\tPrec@5 90.625 (92.376)\n",
      "\t - Epoch: [1][1300/1563]\tTime 0.573 (0.615)\tLoss 0.9622 (1.4212)\tPrec@1 62.500 (48.232)\tPrec@5 96.875 (92.571)\n",
      "\t - Epoch: [1][1400/1563]\tTime 0.661 (0.612)\tLoss 0.9260 (1.4031)\tPrec@1 68.750 (48.978)\tPrec@5 100.000 (92.786)\n",
      "\t - Epoch: [1][1500/1563]\tTime 0.564 (0.610)\tLoss 1.1717 (1.3890)\tPrec@1 62.500 (49.565)\tPrec@5 90.625 (92.944)\n",
      "##### Validation_time 47.054 Prec@1 57.910 Prec@5 94.290 #####\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\t - Epoch: [0][0/1563]\tTime 6.762 (6.762)\tLoss 2.3101 (2.3101)\tPrec@1 21.875 (21.875)\tPrec@5 53.125 (53.125)\n",
      "\t - Epoch: [0][100/1563]\tTime 0.800 (0.881)\tLoss 2.3632 (2.5187)\tPrec@1 0.000 (10.396)\tPrec@5 40.625 (50.650)\n",
      "\t - Epoch: [0][200/1563]\tTime 0.948 (0.844)\tLoss 2.1496 (2.4021)\tPrec@1 21.875 (11.443)\tPrec@5 71.875 (53.856)\n",
      "\t - Epoch: [0][300/1563]\tTime 0.886 (0.835)\tLoss 2.1920 (2.3265)\tPrec@1 25.000 (13.497)\tPrec@5 75.000 (59.230)\n",
      "\t - Epoch: [0][400/1563]\tTime 0.803 (0.828)\tLoss 2.1500 (2.2739)\tPrec@1 9.375 (15.134)\tPrec@5 68.750 (63.178)\n",
      "\t - Epoch: [0][500/1563]\tTime 0.778 (0.824)\tLoss 1.9888 (2.2262)\tPrec@1 25.000 (16.529)\tPrec@5 81.250 (65.899)\n",
      "\t - Epoch: [0][600/1563]\tTime 0.781 (0.822)\tLoss 1.8334 (2.1920)\tPrec@1 31.250 (17.866)\tPrec@5 87.500 (67.861)\n",
      "\t - Epoch: [0][700/1563]\tTime 0.786 (0.820)\tLoss 2.0247 (2.1638)\tPrec@1 34.375 (18.933)\tPrec@5 71.875 (69.370)\n",
      "\t - Epoch: [0][800/1563]\tTime 0.807 (0.819)\tLoss 1.9513 (2.1383)\tPrec@1 31.250 (20.069)\tPrec@5 71.875 (70.697)\n",
      "\t - Epoch: [0][900/1563]\tTime 0.785 (0.819)\tLoss 1.6657 (2.1138)\tPrec@1 43.750 (21.067)\tPrec@5 90.625 (71.872)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t - Epoch: [0][1000/1563]\tTime 0.788 (0.819)\tLoss 1.7804 (2.0923)\tPrec@1 25.000 (21.831)\tPrec@5 87.500 (72.883)\n",
      "\t - Epoch: [0][1100/1563]\tTime 0.792 (0.819)\tLoss 1.6928 (2.0718)\tPrec@1 40.625 (22.624)\tPrec@5 87.500 (73.856)\n",
      "\t - Epoch: [0][1200/1563]\tTime 0.785 (0.818)\tLoss 2.0390 (2.0522)\tPrec@1 34.375 (23.397)\tPrec@5 78.125 (74.768)\n",
      "\t - Epoch: [0][1300/1563]\tTime 0.788 (0.818)\tLoss 1.8812 (2.0344)\tPrec@1 25.000 (24.152)\tPrec@5 75.000 (75.579)\n",
      "\t - Epoch: [0][1400/1563]\tTime 0.803 (0.817)\tLoss 1.7490 (2.0161)\tPrec@1 40.625 (24.946)\tPrec@5 78.125 (76.280)\n",
      "\t - Epoch: [0][1500/1563]\tTime 0.783 (0.817)\tLoss 1.6381 (1.9992)\tPrec@1 40.625 (25.656)\tPrec@5 87.500 (76.932)\n",
      "##### Validation_time 74.642 Prec@1 39.140 Prec@5 88.220 #####\n",
      "\t - Epoch: [1][0/1563]\tTime 6.703 (6.703)\tLoss 1.8182 (1.8182)\tPrec@1 31.250 (31.250)\tPrec@5 84.375 (84.375)\n",
      "\t - Epoch: [1][100/1563]\tTime 0.801 (0.875)\tLoss 1.7814 (1.7186)\tPrec@1 21.875 (35.984)\tPrec@5 90.625 (87.129)\n",
      "\t - Epoch: [1][200/1563]\tTime 0.889 (0.849)\tLoss 1.4909 (1.7133)\tPrec@1 46.875 (36.489)\tPrec@5 93.750 (87.500)\n",
      "\t - Epoch: [1][300/1563]\tTime 0.784 (0.837)\tLoss 1.5084 (1.7099)\tPrec@1 37.500 (36.939)\tPrec@5 96.875 (87.697)\n",
      "\t - Epoch: [1][400/1563]\tTime 0.794 (0.835)\tLoss 1.8089 (1.7032)\tPrec@1 31.250 (37.329)\tPrec@5 84.375 (87.609)\n",
      "\t - Epoch: [1][500/1563]\tTime 1.079 (0.831)\tLoss 1.4302 (1.6838)\tPrec@1 53.125 (38.199)\tPrec@5 96.875 (88.124)\n",
      "\t - Epoch: [1][600/1563]\tTime 0.788 (0.829)\tLoss 1.6515 (1.6697)\tPrec@1 40.625 (38.524)\tPrec@5 90.625 (88.389)\n",
      "\t - Epoch: [1][700/1563]\tTime 0.784 (0.827)\tLoss 1.3655 (1.6527)\tPrec@1 37.500 (39.154)\tPrec@5 90.625 (88.655)\n",
      "\t - Epoch: [1][800/1563]\tTime 0.787 (0.826)\tLoss 1.3580 (1.6429)\tPrec@1 31.250 (39.556)\tPrec@5 100.000 (88.928)\n",
      "\t - Epoch: [1][900/1563]\tTime 0.781 (0.826)\tLoss 1.4294 (1.6293)\tPrec@1 37.500 (40.074)\tPrec@5 93.750 (89.200)\n",
      "\t - Epoch: [1][1000/1563]\tTime 0.807 (0.826)\tLoss 1.7216 (1.6139)\tPrec@1 46.875 (40.647)\tPrec@5 93.750 (89.495)\n",
      "\t - Epoch: [1][1100/1563]\tTime 0.787 (0.825)\tLoss 1.5905 (1.5985)\tPrec@1 50.000 (41.326)\tPrec@5 90.625 (89.663)\n",
      "\t - Epoch: [1][1200/1563]\tTime 0.798 (0.824)\tLoss 1.5262 (1.5828)\tPrec@1 46.875 (41.882)\tPrec@5 96.875 (89.902)\n",
      "\t - Epoch: [1][1300/1563]\tTime 0.787 (0.824)\tLoss 1.2155 (1.5649)\tPrec@1 56.250 (42.602)\tPrec@5 96.875 (90.219)\n",
      "\t - Epoch: [1][1400/1563]\tTime 0.790 (0.823)\tLoss 1.4621 (1.5482)\tPrec@1 46.875 (43.299)\tPrec@5 96.875 (90.451)\n",
      "\t - Epoch: [1][1500/1563]\tTime 0.809 (0.822)\tLoss 1.4992 (1.5305)\tPrec@1 46.875 (43.977)\tPrec@5 93.750 (90.717)\n",
      "##### Validation_time 72.384 Prec@1 50.770 Prec@5 94.630 #####\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\t - Epoch: [0][0/1563]\tTime 6.186 (6.186)\tLoss 2.2666 (2.2666)\tPrec@1 9.375 (9.375)\tPrec@5 71.875 (71.875)\n",
      "\t - Epoch: [0][100/1563]\tTime 0.449 (0.513)\tLoss 2.3113 (2.5039)\tPrec@1 9.375 (10.891)\tPrec@5 46.875 (52.259)\n",
      "\t - Epoch: [0][200/1563]\tTime 0.450 (0.489)\tLoss 2.1053 (2.3660)\tPrec@1 25.000 (13.495)\tPrec@5 68.750 (57.882)\n",
      "\t - Epoch: [0][300/1563]\tTime 0.517 (0.478)\tLoss 2.1801 (2.2801)\tPrec@1 21.875 (15.853)\tPrec@5 62.500 (62.988)\n",
      "\t - Epoch: [0][400/1563]\tTime 0.537 (0.474)\tLoss 2.0559 (2.2267)\tPrec@1 18.750 (17.355)\tPrec@5 68.750 (66.124)\n",
      "\t - Epoch: [0][500/1563]\tTime 0.601 (0.471)\tLoss 1.9523 (2.1836)\tPrec@1 34.375 (18.837)\tPrec@5 71.875 (68.625)\n",
      "\t - Epoch: [0][600/1563]\tTime 0.450 (0.471)\tLoss 1.9267 (2.1507)\tPrec@1 37.500 (20.045)\tPrec@5 78.125 (70.372)\n",
      "\t - Epoch: [0][700/1563]\tTime 0.451 (0.470)\tLoss 1.9599 (2.1178)\tPrec@1 21.875 (21.353)\tPrec@5 78.125 (71.911)\n",
      "\t - Epoch: [0][800/1563]\tTime 0.525 (0.471)\tLoss 1.8820 (2.0946)\tPrec@1 34.375 (22.183)\tPrec@5 75.000 (73.205)\n",
      "\t - Epoch: [0][900/1563]\tTime 0.508 (0.470)\tLoss 1.7611 (2.0670)\tPrec@1 31.250 (23.214)\tPrec@5 90.625 (74.487)\n",
      "\t - Epoch: [0][1000/1563]\tTime 0.531 (0.475)\tLoss 1.7094 (2.0449)\tPrec@1 34.375 (24.135)\tPrec@5 87.500 (75.524)\n",
      "\t - Epoch: [0][1100/1563]\tTime 0.461 (0.476)\tLoss 1.8549 (2.0253)\tPrec@1 28.125 (24.850)\tPrec@5 81.250 (76.357)\n",
      "\t - Epoch: [0][1200/1563]\tTime 0.500 (0.479)\tLoss 1.8837 (2.0056)\tPrec@1 31.250 (25.500)\tPrec@5 75.000 (77.160)\n",
      "\t - Epoch: [0][1300/1563]\tTime 0.476 (0.479)\tLoss 1.7799 (1.9860)\tPrec@1 34.375 (26.206)\tPrec@5 84.375 (77.954)\n",
      "\t - Epoch: [0][1400/1563]\tTime 0.648 (0.481)\tLoss 1.8216 (1.9682)\tPrec@1 25.000 (26.894)\tPrec@5 81.250 (78.593)\n",
      "\t - Epoch: [0][1500/1563]\tTime 0.462 (0.482)\tLoss 1.6344 (1.9529)\tPrec@1 37.500 (27.430)\tPrec@5 87.500 (79.199)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-29df5258f95b>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    105\u001b[0m                                                      \u001b[0mstage_pool_path_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstage_pool_path_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m                                                      \u001b[0mdata_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m                                                      log_file_name=self.log_file_name)\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m                 \u001b[0mnow_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%Y-%m-%d %H:%M:%S'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-3c4115c4367a>\u001b[0m in \u001b[0;36mevaluate_v2_full_train\u001b[1;34m(individual, args_train, stage_pool_path_list, data_path, channels, log_file_name)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[1;31m# train for one epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNN_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_file_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[1;31m# evaluate on validation set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\datascience\\1219_code\\basic_model\\utils_kyy\\train_validate.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(train_loader, model, criterion, optimizer, lr_scheduler, epoch, print_freq, log_file_name)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;31m# compute output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_var\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_var\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\newrw\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\datascience\\1219_code\\basic_model\\utils_kyy\\models.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[1;31m#print(\"==========Conv4  Size\", x.size())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m         \u001b[1;31m#print(\"==========Conv5  Size\", x.size())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\newrw\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\datascience\\1219_code\\basic_model\\utils_kyy\\models.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[1;31m# 따라서, input으로 넣을 때 unpack 함.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m                 \u001b[1;31m# id 작은 노드부터 result를 차근차근 계산하면서, id를 올라감.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m                 \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodeop\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_nodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\newrw\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\datascience\\1219_code\\basic_model\\utils_kyy\\models.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, *input)\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\newrw\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\datascience\\1219_code\\basic_model\\utils_kyy\\models.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\newrw\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\newrw\\lib\\site-packages\\torch\\nn\\modules\\activation.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\newrw\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mthreshold\u001b[1;34m(input, threshold, value, inplace)\u001b[0m\n\u001b[0;32m    838\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.stage_pool_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'newrw'",
   "language": "python",
   "name": "newrw"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
